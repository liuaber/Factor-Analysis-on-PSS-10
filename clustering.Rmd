---
title: "Clustering_JSM_abstract"
author: "Bowen Liu"
date: "4/28/2021"
output: html_document
---

```{r package_prep}
library(factoextra)
library(fpc)
```

```{r data_prep}
setwd("~/Desktop/covid19_survey")
covid = read.csv("covid19_data.csv")
```

## CAS clustering
## Concern: Fail to use the suggested diagnosis threshold (9)
Threshold: <9; >=9 (Natural number of clustering: 2)
Significant Demographic Variables: Q1.1, 5, 6, 11, 24, 25, 26A
## Without Bonferroni control, the significance level is set to be alpha = 0.01
## Clustering: 
Plan A: Label the participants by the suggested scale threshold ("Ground Truth")
Plan B: Create an artificial clustering by using the actual scale questions ("Pseudo Ground Truth")
Suggestion: Go with Plan B. 

```{r cas}
###CAS scale
covid_clu_cas = covid[-c(which(is.na(covid$CAS_1)==TRUE|is.na(covid$CAS_2)==TRUE|is.na(covid$CAS_3)==TRUE|
                             is.na(covid$CAS_4)==TRUE|is.na(covid$CAS_5)==TRUE)),]#1911 left
#Using CAS features
cas_clu = covid_clu_cas[,2:6]
cas_clu = cas_clu-1 
cas_clu.scaled = scale(cas_clu) 
#Determine the no of clusters
# Elbow method for kmeans
fviz_nbclust(cas_clu.scaled, kmeans, method = "wss") +
  geom_vline(xintercept = 3, linetype = 2)+ggtitle("Elbow Method (CAS)")
#3 clusters were recommended
cas.res <- kmeans(cas_clu.scaled, 3, nstart = 10)
cas.res_1 = dbscan(cas_clu,eps = 1)
fviz_cluster(cas.res, cas_clu, geom = "point",ellipse.type = "norm",main = "Clustering using 5 features from CAS (k-means)")
fviz_cluster(cas.res_1, cas_clu, geom = "point",ellipse.type = "norm",main = "Clustering using 5 features from CAS (DBSCAN)")
### Feature CAS score calculation
attach(covid_clu_cas)
covid_clu_cas$CAS_total = CAS_1+CAS_2+CAS_3+CAS_4+ CAS_5 -5 #-5 for the reasons we stated above
detach(covid_clu_cas)
mean(covid_clu_cas$CAS_total[c(which(cas.res_1$cluster == 0))])
mean(covid_clu_cas$CAS_total[c(which(cas.res_1$cluster == 1))])
#Not separable
```

## PSS clustering
## Concern: Fail to use the suggested diagnosis threshold (9)
Threshold: (0,13];(13,27);[28,.) (Natural number of clustering: 2)
Significant Demographic Variables: Q1.1, 5, 6, 11, 24, 25, 26A
## Without Bonferroni control, the significance level is set to be alpha = 0.01
## Clustering: 
Plan A: Label the participants by the suggested scale threshold ("Ground Truth")
Plan B: Create an artificial clustering by using the actual scale questions ("Pseudo Ground Truth")
Suggestion: Go with Plan B. 
Elbow method is chosen to choose the natural number of clustering for k-means; if DBSCAN was used, then this step should be omitted 
```{r PSS}
### cl pss: Data arrangement
covid_clu_pss = covid[-c(which(is.na(covid$PSS_1)==TRUE|is.na(covid$PSS_2)==TRUE|is.na(covid$PSS_3)==TRUE|
                             is.na(covid$PSS_4)==TRUE|is.na(covid$PSS_5)==TRUE|is.na(covid$PSS_6)==TRUE|is.na(covid$PSS_7)==TRUE|is.na(covid$PSS_8)==TRUE|is.na(covid$PSS_9)==TRUE
                           |is.na(covid$PSS_10)==TRUE)),]
dim(covid_clu_pss)
#There are 1738 our 2091 responses completed the whole PSS scale. 
#Then keep the ones that completed the corresponding demographics questions:
#Q1.1, 5, 6, 11, 24, 25, 26A (29,36,37,44,62,63,64)
covid_clu_pss = covid_clu_pss[-c(which(is.na(covid_clu_pss$Q5)==TRUE|is.na(covid_clu_pss$Q6)==TRUE|is.na(covid_clu_pss$Q1.1)==TRUE|is.na(covid_clu_pss$Q11)==TRUE|is.na(covid_clu_pss$Q24)==TRUE|is.na(covid_clu_pss$Q25)==TRUE|is.na(covid_clu_pss$Q26A)==TRUE)),]
dim(covid_clu_pss)
#Among 1738 participants who completed the PSS scale, 1700 completed the corresponding questions. 
#Part 1: Using 10 PSS questions:
pss_clu = covid_clu_pss[,19:28]
pss_clu$PSS_1 = pss_clu$PSS_1-1
pss_clu$PSS_2 = pss_clu$PSS_2-1
pss_clu$PSS_3 = pss_clu$PSS_3-1
pss_clu$PSS_6 = pss_clu$PSS_6-1
pss_clu$PSS_9 = pss_clu$PSS_9-1
pss_clu$PSS_10 = pss_clu$PSS_10-1
pss_clu$PSS_4 = 5-pss_clu$PSS_4
pss_clu$PSS_5 = 5-pss_clu$PSS_5
pss_clu$PSS_7 = 5-pss_clu$PSS_7
pss_clu$PSS_8 = 5-pss_clu$PSS_8
pss_clu.scaled = scale(pss_clu) 
fviz_nbclust(pss_clu.scaled, kmeans, method = "wss") +
  geom_vline(xintercept = 3, linetype = 2)+ggtitle("Elbow Method (PSS)")
pss.res <- kmeans(pss_clu.scaled, 3, nstart = 10)
fviz_cluster(pss.res, pss_clu, ellipse.type = "norm")
fviz_cluster(pss.res, pss_clu, geom = "point",ellipse.type = "norm",main = "Clustering using 10 features from PSS")
#Part 2: 
demo_pss_clu = covid_clu_pss[,c(29,36,37,44,62,63,64)]
demo_pss_clu.scaled = scale(demo_pss_clu) 
fviz_nbclust(demo_pss_clu.scaled, kmeans, method = "wss") +
  geom_vline(xintercept = 3, linetype = 2)+ggtitle("Elbow Method (PSS)")
demo_pss.res <- kmeans(demo_pss_clu.scaled, 3, nstart = 10)
fviz_cluster(demo_pss.res, demo_pss_clu, ellipse.type = "norm")
fviz_cluster(demo_pss.res, demo_pss_clu, geom = "point",ellipse.type = "norm",main = "Clustering using 10 features from PSS")
#Part 3: Obtain the mean of each cluster so a cluster matching can be done. 
#Obtain the PSS score for 1700 participants
attach(covid_clu_pss)
covid_clu_pss$PSS_total = (PSS_1+PSS_2+PSS_3+ PSS_6+PSS_9+PSS_10 -6)+(5-PSS_4)+(5-PSS_5)+(5-PSS_7)+(5-PSS_8) 
detach(covid_clu_pss)
#Get a summary for the mean PSS score for both clustering: (pss.res; demo_pss.res)
mean(covid_clu_pss$PSS_total[c(which(pss.res$cluster == 1))])#Mean = 29 #high stress
mean(covid_clu_pss$PSS_total[c(which(pss.res$cluster == 2))])#Mean = 10 #low stress
mean(covid_clu_pss$PSS_total[c(which(pss.res$cluster == 3))])#Mean = 20 #medium stress
#Somehow the above have the ability to categorize the participants into 3 'separable' groups
mean(covid_clu_pss$PSS_total[c(which(demo_pss.res$cluster == 1))])
mean(covid_clu_pss$PSS_total[c(which(demo_pss.res$cluster == 2))])
mean(covid_clu_pss$PSS_total[c(which(demo_pss.res$cluster == 3))])
```




```{r pressure, echo=FALSE}

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
